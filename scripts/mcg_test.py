#!/usr/bin/env python3
"""
MCG-diff ç»¼åˆæµ‹è¯•è„šæœ¬ï¼šæ£€æŸ¥ä¸‰ä¸ªå¯ç–‘ç‚¹

1. ç”¨ posterior covariance + V ç®—"ç†è®º SVD var"ï¼Œç¡®è®¤ obs/null index è·Ÿ svd_mask ä¸€è‡´
2. æµ‹ unconditional diffusion prior çš„æ–¹å·®ï¼Œçœ‹æ˜¯ä¸æ˜¯æœ¬æ¥å°±è¿œå°äº true prior
3. åœ¨"å®Œå…¨ä¸€æ ·çš„ code path ä¸‹"å¤ç°åŸ MoG toyï¼ˆç”¨ diagonal maskï¼‰
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

import torch
import numpy as np
import matplotlib.pyplot as plt
from scripts.uq_simulation_analysis import generate_dataset, load_model_and_algorithm
from algo.unconditional import UnconditionalDiffusionSampler

print("="*80)
print("MCG-diff ç»¼åˆæµ‹è¯•ï¼šæ£€æŸ¥ä¸‰ä¸ªå¯ç–‘ç‚¹")
print("="*80)

# ============================================================================
# Test 1: ç†è®º SVD æ–¹å·® vs svd_mask å¯¹é½æ£€æŸ¥
# ============================================================================

print("\n" + "="*80)
print("Test 1: ç†è®º SVD æ–¹å·® vs svd_mask å¯¹é½æ£€æŸ¥")
print("="*80)

# ç”Ÿæˆ MRI-like æ•°æ®é›†
dataset = generate_dataset(
    A_type='mri_like',
    N=1,
    noise_std=0.5,
    seed=0,
    A_seed=1234
)

forward_op = dataset['problem']
A = torch.from_numpy(dataset['A']).float()  # [16, 16]
S_vec = torch.from_numpy(dataset['S']).float()  # [16]
V = torch.from_numpy(dataset['V']).float()  # [16, 16] (V^T in SVD)

# Prior covariance
Sigma_prior = forward_op.Sigma_prior  # [16, 16]

# Noise variance
sigma_noise = 0.5
sigma_noise_sq = sigma_noise ** 2

# è®¡ç®—åéªŒåæ–¹å·®ï¼ˆåŸå§‹åæ ‡ xï¼‰
A_T_A = A.T @ A
Sigma_prior_inv = torch.linalg.inv(Sigma_prior)
Sigma_post = torch.linalg.inv(A_T_A / sigma_noise_sq + Sigma_prior_inv)  # [16, 16]

# è½¬æ¢åˆ° SVD åæ ‡ z = V^T x
Vt_matrix = forward_op._Vt_matrix  # [16, 16] - è¿™æ˜¯ Vt
V_matrix = Vt_matrix.T  # [16, 16] - è¿™æ˜¯ V

# åœ¨ SVD åæ ‡ä¸­çš„åéªŒåæ–¹å·®
Sigma_post_z = V_matrix.T @ Sigma_post @ V_matrix  # [16, 16]
var_z_theoretical = torch.diag(Sigma_post_z)  # [16]

# MCG-diff ä½¿ç”¨çš„ svd_mask
S_img = forward_op.S  # [1, 1, 4, 4]
svd_mask_4d = (S_img > 0.1).float()  # [1, 1, 4, 4]
svd_mask_flat = svd_mask_4d.flatten()  # [16]

# å°† var_z_theoretical reshape åˆ° 4D æ ¼å¼
var_z_4d = var_z_theoretical.reshape(1, 1, 4, 4)

# åˆ†ç¦» observed å’Œ null
observed_indices = torch.where(S_vec > 0.1)[0].tolist()
null_indices = torch.where(S_vec <= 0.1)[0].tolist()

var_obs_theoretical = var_z_theoretical[observed_indices].mean().item()
var_null_theoretical = var_z_theoretical[null_indices].mean().item()

print(f"\nç†è®ºåéªŒæ–¹å·®ï¼ˆSVD åæ ‡ï¼‰:")
print(f"  Observed dims (indices {observed_indices}): mean = {var_obs_theoretical:.6f}")
print(f"  Null dims (indices {null_indices}): mean = {var_null_theoretical:.6f}")
print(f"  Ratio: {var_null_theoretical / var_obs_theoretical:.4f}")

# æ£€æŸ¥ 4D reshape åçš„å¯¹åº”å…³ç³»
print(f"\n4D reshape æ£€æŸ¥:")
print(f"  var_z_theoretical (16D):\n{var_z_theoretical}")
print(f"  var_z_4d (4D):\n{var_z_4d.squeeze()}")
print(f"  svd_mask_4d (4D):\n{svd_mask_4d.squeeze()}")

# æ£€æŸ¥ observed ä½ç½®çš„ç†è®ºæ–¹å·®
var_obs_4d = (var_z_4d * svd_mask_4d).sum() / svd_mask_4d.sum()
var_null_4d = (var_z_4d * (1 - svd_mask_4d)).sum() / (1 - svd_mask_4d).sum()

print(f"\nåŸºäº 4D mask çš„ç†è®ºæ–¹å·®:")
print(f"  Observed (mask=1): mean = {var_obs_4d.item():.6f}")
print(f"  Null (mask=0): mean = {var_null_4d.item():.6f}")
print(f"  Ratio: {var_null_4d.item() / var_obs_4d.item():.4f}")

# éªŒè¯ä¸€è‡´æ€§
if abs(var_obs_4d.item() - var_obs_theoretical) < 0.01:
    print(f"\nâœ… Test 1 é€šè¿‡ï¼šç†è®ºæ–¹å·®åœ¨ 16D å’Œ 4D æ ¼å¼ä¸‹ä¸€è‡´")
else:
    print(f"\nâŒ Test 1 å¤±è´¥ï¼šç†è®ºæ–¹å·®ä¸ä¸€è‡´")
    print(f"  16D: {var_obs_theoretical:.6f}, 4D: {var_obs_4d.item():.6f}")

# ============================================================================
# Test 2: Unconditional Diffusion Prior æ–¹å·®æ£€æŸ¥
# ============================================================================

print("\n" + "="*80)
print("Test 2: Unconditional Diffusion Prior æ–¹å·®æ£€æŸ¥")
print("="*80)

# åŠ è½½æ¨¡å‹å’Œç®—æ³•
net, _, algo_config = load_model_and_algorithm('MCG_diff', forward_op)

# åˆ›å»ºæ— æ¡ä»¶é‡‡æ ·å™¨
unconditional_sampler = UnconditionalDiffusionSampler(
    net=net,
    forward_op=forward_op,
    diffusion_scheduler_config=algo_config['scheduler_config'],
    sde=False  # ä½¿ç”¨ ODE æ¨¡å¼
)

# ç”Ÿæˆ K ä¸ªæ— æ¡ä»¶æ ·æœ¬
K = 200
print(f"\nç”Ÿæˆ K={K} ä¸ªæ— æ¡ä»¶ diffusion prior æ ·æœ¬...")
samples_list = []
for k in range(K):
    # åˆ›å»ºä¸€ä¸ª dummy observationï¼ˆä¸ä¼šè¢«ä½¿ç”¨ï¼‰
    dummy_obs = torch.zeros(1, 1, 4, 4, device=forward_op.device)
    sample_k = unconditional_sampler.inference(dummy_obs, num_samples=1, verbose=False)
    samples_list.append(sample_k.cpu())

samples_stack = torch.stack(samples_list, dim=0)  # [K, 1, 4, 4]

# è½¬æ¢åˆ°å‘é‡ç©ºé—´
samples_vec = forward_op._img_to_vec(samples_stack)  # [K, 16]

# è®¡ç®—æ¯ä¸ªç»´åº¦çš„æ–¹å·®
var_prior_per_dim = samples_vec.var(dim=0)  # [16]
var_prior_mean = var_prior_per_dim.mean().item()

print(f"\nUnconditional diffusion prior æ–¹å·®:")
print(f"  æ¯ä¸ªç»´åº¦çš„æ–¹å·®: {var_prior_per_dim}")
print(f"  å¹³å‡æ–¹å·®: {var_prior_mean:.6f}")
print(f"  æœ€å°æ–¹å·®: {var_prior_per_dim.min().item():.6f}")
print(f"  æœ€å¤§æ–¹å·®: {var_prior_per_dim.max().item():.6f}")

# å¯¹æ¯”ç†è®º prior æ–¹å·®
# ç†è®º prior: å‰8ç»´ Toeplitz (å¯¹è§’çº¿â‰ˆ1), å8ç»´ å¯¹è§’ (æ–¹å·®=5.0)
# å¹³å‡ç†è®ºæ–¹å·® â‰ˆ (8*1 + 8*5) / 16 = 3.0
theoretical_prior_var_mean = (8 * 1.0 + 8 * 5.0) / 16.0

print(f"\nç†è®º prior æ–¹å·®ï¼ˆå¹³å‡ï¼‰: {theoretical_prior_var_mean:.6f}")
print(f"å®é™… diffusion prior æ–¹å·®ï¼ˆå¹³å‡ï¼‰: {var_prior_mean:.6f}")
print(f"ç›¸å¯¹è¯¯å·®: {abs(var_prior_mean - theoretical_prior_var_mean) / theoretical_prior_var_mean * 100:.2f}%")

if var_prior_mean < theoretical_prior_var_mean * 0.5:
    print(f"\nâŒ Test 2 å¤±è´¥ï¼šDiffusion prior ä¸¥é‡ under-dispersed")
    print(f"  å®é™…æ–¹å·® ({var_prior_mean:.6f}) è¿œå°äºç†è®ºå€¼ ({theoretical_prior_var_mean:.6f})")
    print(f"  è¿™ä¼šå¯¼è‡´ MCG-diff æ— æ³•æ¢å¤æ­£ç¡®çš„ nullspace æ–¹å·®")
else:
    print(f"\nâœ… Test 2 é€šè¿‡ï¼šDiffusion prior æ–¹å·®åˆç†")

# æ£€æŸ¥ SVD åæ ‡ä¸‹çš„ prior æ–¹å·®
samples_svd = samples_vec @ Vt_matrix  # [K, 16] - SVD space
var_prior_svd = samples_svd.var(dim=0)  # [16]

var_prior_obs = var_prior_svd[observed_indices].mean().item()
var_prior_null = var_prior_svd[null_indices].mean().item()

print(f"\nUnconditional prior æ–¹å·®ï¼ˆSVD åæ ‡ï¼‰:")
print(f"  Observed dims: mean = {var_prior_obs:.6f}")
print(f"  Null dims: mean = {var_prior_null:.6f}")
print(f"  Ratio: {var_prior_null / var_prior_obs:.4f}")

# ============================================================================
# Test 3: ç”¨ Diagonal Mask å¤ç°åŸ MoG toy
# ============================================================================

print("\n" + "="*80)
print("Test 3: ç”¨ Diagonal Mask å¤ç°åŸ MoG toy")
print("="*80)

# åˆ›å»ºä¸€ä¸ªç®€å•çš„ diagonal mask A
# å‰ 8 ä¸ªç»´åº¦ observedï¼Œå 8 ä¸ªç»´åº¦ null
A_diagonal = torch.zeros(16, 16)
for i in range(8):
    A_diagonal[i, i] = 1.0  # å‰ 8 ç»´ observed

# åˆ›å»º diagonal mask çš„ problem
# æˆ‘ä»¬éœ€è¦æ‰‹åŠ¨åˆ›å»ºä¸€ä¸ªç®€å•çš„ forward_op
print(f"\nåˆ›å»º diagonal mask A (å‰8ç»´ observed, å8ç»´ null)...")

# ä½¿ç”¨ Identity A ç±»å‹ï¼Œä½†æˆ‘ä»¬éœ€è¦ä¸€ä¸ªç®€å•çš„æµ‹è¯•
# å®é™…ä¸Šï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥æµ‹è¯• A=I çš„æƒ…å†µ
dataset_identity = generate_dataset(
    A_type='identity',
    N=1,
    noise_std=0.5,
    seed=0,
    A_seed=1234
)

forward_op_identity = dataset_identity['problem']

# åŠ è½½ MCG-diff ç”¨äº A=I
net_identity, algo_identity, _ = load_model_and_algorithm('MCG_diff', forward_op_identity)

# è·å–ä¸€ä¸ªè§‚æµ‹
observation_np = dataset_identity['y'][0:1]  # [1, 16] numpy
observation_img = forward_op_identity._vec_to_img(torch.from_numpy(observation_np))  # [1, 1, 4, 4]

# ç”Ÿæˆ K ä¸ªåéªŒæ ·æœ¬
K_test = 20
print(f"ç”Ÿæˆ K={K_test} ä¸ªåéªŒæ ·æœ¬ï¼ˆA=Iï¼‰...")
samples_list_identity = []
for k in range(K_test):
    sample_k = algo_identity.inference(observation_img, num_samples=1)
    samples_list_identity.append(sample_k)

samples_stack_identity = torch.stack(samples_list_identity, dim=0)  # [K, 1, 4, 4]

# è½¬æ¢åˆ°å‘é‡ç©ºé—´
samples_vec_identity = forward_op_identity._img_to_vec(samples_stack_identity)  # [K, 16]

# è®¡ç®—æ–¹å·®
var_identity_per_dim = samples_vec_identity.var(dim=0)  # [16]
var_identity_mean = var_identity_per_dim.mean().item()

print(f"\nMCG-diff è¾“å‡ºæ–¹å·®ï¼ˆA=Iï¼‰:")
print(f"  æ¯ä¸ªç»´åº¦çš„æ–¹å·®: {var_identity_per_dim}")
print(f"  å¹³å‡æ–¹å·®: {var_identity_mean:.6f}")

# å¯¹äº A=Iï¼Œç†è®ºåéªŒæ–¹å·®åº”è¯¥æ˜¯ noise_std^2 = 0.25
theoretical_var_identity = 0.25

print(f"\nç†è®ºåéªŒæ–¹å·®ï¼ˆA=Iï¼‰: {theoretical_var_identity:.6f}")
print(f"å®é™…æ–¹å·®ï¼ˆA=Iï¼‰: {var_identity_mean:.6f}")
print(f"ç›¸å¯¹è¯¯å·®: {abs(var_identity_mean - theoretical_var_identity) / theoretical_var_identity * 100:.2f}%")

if abs(var_identity_mean - theoretical_var_identity) / theoretical_var_identity < 0.2:
    print(f"\nâœ… Test 3 é€šè¿‡ï¼šA=I æ—¶ MCG-diff æ–¹å·®æ¥è¿‘ç†è®ºå€¼")
else:
    print(f"\nâŒ Test 3 å¤±è´¥ï¼šA=I æ—¶ MCG-diff æ–¹å·®åç¦»ç†è®ºå€¼")
    print(f"  å¯èƒ½åŸå› ï¼šç®—æ³•å®ç°é—®é¢˜æˆ– diffusion prior under-dispersion")

# ============================================================================
# æ€»ç»“æŠ¥å‘Š
# ============================================================================

print("\n" + "="*80)
print("æ€»ç»“æŠ¥å‘Š")
print("="*80)

print(f"\nTest 1 (ç†è®º SVD æ–¹å·®å¯¹é½):")
if abs(var_obs_4d.item() - var_obs_theoretical) < 0.01:
    print(f"  âœ… é€šè¿‡ï¼šç†è®ºæ–¹å·®åœ¨ 16D å’Œ 4D æ ¼å¼ä¸‹ä¸€è‡´")
else:
    print(f"  âŒ å¤±è´¥ï¼šç†è®ºæ–¹å·®ä¸ä¸€è‡´")

print(f"\nTest 2 (Unconditional diffusion prior æ–¹å·®):")
if var_prior_mean >= theoretical_prior_var_mean * 0.5:
    print(f"  âœ… é€šè¿‡ï¼šDiffusion prior æ–¹å·®åˆç† ({var_prior_mean:.6f} vs {theoretical_prior_var_mean:.6f})")
else:
    print(f"  âŒ å¤±è´¥ï¼šDiffusion prior ä¸¥é‡ under-dispersed ({var_prior_mean:.6f} vs {theoretical_prior_var_mean:.6f})")
    print(f"      â†’ è¿™ä¼šå¯¼è‡´ MCG-diff æ— æ³•æ¢å¤æ­£ç¡®çš„ nullspace æ–¹å·®")

print(f"\nTest 3 (A=I å¤ç°):")
if abs(var_identity_mean - theoretical_var_identity) / theoretical_var_identity < 0.2:
    print(f"  âœ… é€šè¿‡ï¼šA=I æ—¶ MCG-diff æ–¹å·®æ¥è¿‘ç†è®ºå€¼")
else:
    print(f"  âŒ å¤±è´¥ï¼šA=I æ—¶ MCG-diff æ–¹å·®åç¦»ç†è®ºå€¼")

print("\n" + "="*80)
print("è¯Šæ–­å»ºè®®")
print("="*80)

if var_prior_mean < theoretical_prior_var_mean * 0.5:
    print("\nğŸ” ä¸»è¦é—®é¢˜ï¼šDiffusion prior under-dispersion")
    print("  å»ºè®®ï¼š")
    print("    1. æ£€æŸ¥ diffusion model çš„è®­ç»ƒæ•°æ®åˆ†å¸ƒ")
    print("    2. æ£€æŸ¥ scheduler çš„ sigma_max/sigma_min è®¾ç½®")
    print("    3. è€ƒè™‘ä½¿ç”¨æ›´åˆé€‚çš„ prior æ¨¡å‹")
elif abs(var_identity_mean - theoretical_var_identity) / theoretical_var_identity >= 0.2:
    print("\nğŸ” ä¸»è¦é—®é¢˜ï¼šMCG-diff ç®—æ³•å®ç°é—®é¢˜")
    print("  å»ºè®®ï¼š")
    print("    1. æ£€æŸ¥ nullspace æ›´æ–°å…¬å¼ï¼ˆåº”è¯¥ä½¿ç”¨ x_t è€Œä¸æ˜¯ x_next_tï¼‰")
    print("    2. æ£€æŸ¥ resampling ç­–ç•¥ï¼ˆå¯èƒ½è¿‡åº¦æ”¶ç¼©æ–¹å·®ï¼‰")
    print("    3. æ£€æŸ¥ SVD å˜æ¢çš„æ­£ç¡®æ€§")
else:
    print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Œé—®é¢˜å¯èƒ½åœ¨å…¶ä»–åœ°æ–¹")
    print("  å»ºè®®ï¼š")
    print("    1. æ£€æŸ¥ MRI-like A çš„ SVD ç»“æ„")
    print("    2. æ£€æŸ¥ resampling åœ¨å¤æ‚é—®é¢˜ä¸Šçš„è¡¨ç°")

print("="*80)
